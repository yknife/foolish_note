### 生产数据

```scala
object MockData {

  // 时间戳 区域 城市 用户 广告
  def mock():ListBuffer[String] = {
    val list: ListBuffer[String] = ListBuffer[String]()
    val areaList = ListBuffer[String]("华北", "华东", "华南")
    val cityList = ListBuffer[String]("北京", "上海", "深圳")
    for(i <- 1 to 30) {
      val area: String = areaList(new Random().nextInt(areaList.size))
      val city = cityList(new Random().nextInt(cityList.size))
      val userId = new Random().nextInt(6) + 1
      val adId = new Random().nextInt(6) + 1
      list.append(s"${System.currentTimeMillis()} ${area} ${city} ${userId} ${adId}")
    }
    list
  }
  def main(args: Array[String]): Unit = {

    // 创建配置对象
    val prop = new Properties()
    // 添加配置
    prop.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, "localhost:9092")
    prop.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,
      "org.apache.kafka.common.serialization.StringSerializer")
    prop.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,
      "org.apache.kafka.common.serialization.StringSerializer")
    // 根据配置创建 Kafka 生产者
    val producer = new KafkaProducer[String, String](prop)
    while (true){
      mock().foreach(
        r=>{
          val record = new ProducerRecord[String,String]("test_topic", r)
          producer.send(record)
        }
      )
    }
  }
}
```

### 消费数据

```scala
object KafkaSourceExample {
  def main(args: Array[String]): Unit = {
    val sparkConf = new
        SparkConf().setMaster("local[*]").setAppName("KafkaSource")
    val ssc = new StreamingContext(sparkConf, Seconds(3))
    val kafkaPara: Map[String, Object] = Map[String, Object](
      ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG ->
        "localhost:9092",
      ConsumerConfig.GROUP_ID_CONFIG -> "test_group",
      "key.deserializer" ->
        "org.apache.kafka.common.serialization.StringDeserializer",
      "value.deserializer" ->
        "org.apache.kafka.common.serialization.StringDeserializer"
    )

    val kafkaDStream: InputDStream[ConsumerRecord[String, String]] = KafkaUtils.createDirectStream[String, String](
      ssc,
      LocationStrategies.PreferConsistent,
      ConsumerStrategies.Subscribe[String, String](Set("test_topic"), kafkaPara)
    )
    kafkaDStream.map(_.value()).print()
    ssc.start()
    ssc.awaitTermination()
  }
}
```